{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D233hR4YBwI9"
   },
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:26:42.572919Z",
     "iopub.status.busy": "2022-09-04T06:26:42.572330Z",
     "iopub.status.idle": "2022-09-04T06:26:43.910450Z",
     "shell.execute_reply": "2022-09-04T06:26:43.909825Z",
     "shell.execute_reply.started": "2022-09-04T06:26:42.572856Z"
    },
    "id": "sUzKZqTuNrei"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from optuna import Trial\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None) # <==== 경고를 끈다\n",
    "\n",
    "filename = 'data/train.csv'\n",
    "data_train = pd.read_csv(filename)\n",
    "\n",
    "filename = 'data/test.csv'\n",
    "data_test = pd.read_csv(filename)\n",
    "\n",
    "filename = 'data/sample_submission.csv'\n",
    "submission = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9n-uV6m5k5o"
   },
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDjltRHSQanX"
   },
   "source": [
    "### 데이터 target 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_mode(df, col):\n",
    "\n",
    "  cnt = Counter(df[col])\n",
    "  list_cnt = cnt.most_common(3)\n",
    "\n",
    "  for idx, value in enumerate(list_cnt):\n",
    "\n",
    "    print(f'{col}의 최빈값 {idx+1}순위 : {value[0]} & {value[-1]}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(df, col):\n",
    "\n",
    "  max = df['착과량(int)'].max()\n",
    "  min = df['착과량(int)'].min()\n",
    "  mean = df['착과량(int)'].mean()\n",
    "  median = df['착과량(int)'].median()\n",
    "\n",
    "  print(f'{col}의 최대값 : {max}')\n",
    "  print(f'{col}의 최소값 : {min}')\n",
    "  print(f'{col}의 평균값 : {mean}')\n",
    "  print(f'{col}의 중앙값 : {median}')\n",
    "  print_mode(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_hist(df, col):\n",
    "\n",
    "  sns.histplot(data=df[col], kde=True)\n",
    "  print_statistics(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1X7L8C7BWxr"
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.637777Z",
     "iopub.status.busy": "2022-09-04T06:27:00.637613Z",
     "iopub.status.idle": "2022-09-04T06:27:00.663571Z",
     "shell.execute_reply": "2022-09-04T06:27:00.662960Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.637762Z"
    },
    "id": "tKO_Zv1O9uJl"
   },
   "outputs": [],
   "source": [
    "#학습, 정답데이터 분리\n",
    "y_train = data_train['착과량(int)']\n",
    "X_drop_list = ['ID']\n",
    "X_train = data_train.drop(X_drop_list, axis = 1)\n",
    "X_test = data_test.drop([\"ID\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "high_corr = data_train.corr().abs().sort_values(by='착과량(int)',ascending=False).iloc[:,:1]\n",
    "features_name = high_corr[high_corr['착과량(int)']>0.9].index\n",
    "features_name = list(features_name)\n",
    "features_name.remove('착과량(int)')\n",
    "X,y = X_train.drop(['착과량(int)'], axis=1) , X_train['착과량(int)']\n",
    "\n",
    "X = X[features_name]\n",
    "X_test = X_test[features_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuD60l6ZcB0Y"
   },
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBQV42MXPAeW"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpFjUI21Uxoo"
   },
   "source": [
    "### nmae score metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base version\n",
    "def NMAE(true, pred):\n",
    "    mae = np.mean(np.abs(true - pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score\n",
    "\n",
    "#cross_val custom version\n",
    "def NMAE_CV(clf, x, y):\n",
    "    pred = clf.predict(x)\n",
    "    mae = np.mean(np.abs(y - pred))\n",
    "    score = mae / np.mean(np.abs(y))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabnetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = X.to_numpy()\n",
    "y_numpy = y.to_numpy().reshape(-1, 1)\n",
    "X_test_numpy = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 203345.26562| val_0_mae: 402.7505| val_1_mae: 422.28811|  0:00:00s\n",
      "epoch 100| loss: 39135.34375| val_0_mae: 354.7546| val_1_mae: 369.82226|  0:00:23s\n",
      "epoch 200| loss: 2019.44006| val_0_mae: 121.28349| val_1_mae: 124.46096|  0:00:48s\n",
      "epoch 300| loss: 2294.80908| val_0_mae: 62.30393| val_1_mae: 64.05749|  0:01:11s\n",
      "epoch 400| loss: 1717.67786| val_0_mae: 42.46077| val_1_mae: 45.82905|  0:01:39s\n",
      "epoch 500| loss: 1609.23145| val_0_mae: 32.93927| val_1_mae: 36.49594|  0:02:01s\n",
      "epoch 600| loss: 1712.651| val_0_mae: 30.76131| val_1_mae: 34.77767|  0:02:24s\n",
      "epoch 700| loss: 1515.26062| val_0_mae: 32.61277| val_1_mae: 37.2843 |  0:02:47s\n",
      "\n",
      "Early stopping occurred at epoch 759 with best_epoch = 659 and best_val_1_mae = 33.82723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold NMAE = 0.0801673056814221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 211312.4375| val_0_mae: 402.53396| val_1_mae: 392.62421|  0:00:00s\n",
      "epoch 100| loss: 36723.79297| val_0_mae: 347.7819| val_1_mae: 342.34951|  0:00:21s\n",
      "epoch 200| loss: 2061.04175| val_0_mae: 134.3287| val_1_mae: 131.72351|  0:00:45s\n",
      "epoch 300| loss: 1722.75049| val_0_mae: 62.4487 | val_1_mae: 62.02265|  0:01:07s\n",
      "epoch 400| loss: 1681.07629| val_0_mae: 34.57418| val_1_mae: 35.25857|  0:01:28s\n",
      "epoch 500| loss: 1478.57336| val_0_mae: 32.43366| val_1_mae: 34.6181 |  0:01:50s\n",
      "\n",
      "Early stopping occurred at epoch 590 with best_epoch = 490 and best_val_1_mae = 32.80224\n",
      "2 Fold NMAE = 0.08243247081546284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 215585.65625| val_0_mae: 407.09006| val_1_mae: 406.43246|  0:00:00s\n",
      "epoch 100| loss: 53010.82031| val_0_mae: 350.42987| val_1_mae: 348.85384|  0:00:22s\n",
      "epoch 200| loss: 2175.54956| val_0_mae: 133.11708| val_1_mae: 132.2091|  0:00:45s\n",
      "epoch 300| loss: 1871.99731| val_0_mae: 54.58124| val_1_mae: 54.33198|  0:01:10s\n",
      "epoch 400| loss: 2183.92358| val_0_mae: 40.19396| val_1_mae: 42.38471|  0:01:30s\n",
      "epoch 500| loss: 1629.64856| val_0_mae: 35.70734| val_1_mae: 36.06475|  0:01:51s\n",
      "epoch 600| loss: 1973.84399| val_0_mae: 30.39876| val_1_mae: 32.9873 |  0:02:11s\n",
      "\n",
      "Early stopping occurred at epoch 659 with best_epoch = 559 and best_val_1_mae = 31.38987\n",
      "3 Fold NMAE = 0.07754606987753823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 214145.21875| val_0_mae: 403.4314| val_1_mae: 392.13838|  0:00:00s\n",
      "epoch 100| loss: 43178.80469| val_0_mae: 361.10901| val_1_mae: 355.18266|  0:00:20s\n",
      "epoch 200| loss: 2109.64062| val_0_mae: 126.98974| val_1_mae: 126.92378|  0:00:40s\n",
      "epoch 300| loss: 2040.71375| val_0_mae: 57.7657 | val_1_mae: 57.37012|  0:01:01s\n",
      "epoch 400| loss: 2035.45044| val_0_mae: 38.05   | val_1_mae: 37.93187|  0:01:24s\n",
      "epoch 500| loss: 1849.74268| val_0_mae: 33.43479| val_1_mae: 34.17388|  0:01:46s\n",
      "epoch 600| loss: 1827.00146| val_0_mae: 34.3097 | val_1_mae: 35.55346|  0:02:07s\n",
      "epoch 700| loss: 1767.39392| val_0_mae: 36.47344| val_1_mae: 36.82667|  0:02:28s\n",
      "epoch 800| loss: 1718.22559| val_0_mae: 39.00296| val_1_mae: 39.54649|  0:02:48s\n",
      "\n",
      "Early stopping occurred at epoch 829 with best_epoch = 729 and best_val_1_mae = 32.97515\n",
      "4 Fold NMAE = 0.08299847028470969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 210957.1875| val_0_mae: 400.54213| val_1_mae: 402.64625|  0:00:00s\n",
      "epoch 100| loss: 36372.99219| val_0_mae: 347.07001| val_1_mae: 347.60476|  0:00:20s\n",
      "epoch 200| loss: 2015.81348| val_0_mae: 153.96324| val_1_mae: 150.5215|  0:00:42s\n",
      "epoch 300| loss: 1804.32593| val_0_mae: 60.16805| val_1_mae: 60.83061|  0:01:02s\n",
      "epoch 400| loss: 1538.42896| val_0_mae: 38.1356 | val_1_mae: 38.34777|  0:01:22s\n",
      "epoch 500| loss: 1620.7533| val_0_mae: 34.36039| val_1_mae: 35.87216|  0:01:42s\n",
      "epoch 600| loss: 1507.26331| val_0_mae: 34.45522| val_1_mae: 37.59365|  0:02:01s\n",
      "\n",
      "Early stopping occurred at epoch 656 with best_epoch = 556 and best_val_1_mae = 33.16234\n",
      "5 Fold NMAE = 0.08147122909996443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daro9\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVG of NMAE = 0.08092310915181947\n"
     ]
    }
   ],
   "source": [
    "tab_pred = []\n",
    "i = 0\n",
    "tab_nmae = []\n",
    "\n",
    "for tr_idx, val_idx in skf.split(X_numpy, y_numpy):\n",
    "    \n",
    "    tr_x, tr_y = X_numpy[tr_idx], y_numpy[tr_idx]\n",
    "    val_x, val_y = X_numpy[val_idx], y_numpy[val_idx]\n",
    "\n",
    "    tab = TabNetRegressor(verbose = 100,seed = 42,optimizer_fn=torch.optim.AdamW)\n",
    "    tab.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], patience=100, max_epochs=2000, eval_metric = ['mae'])\n",
    "\n",
    "    val_pred = tab.predict(val_x).astype(int)\n",
    "    fold_nmae = NMAE(val_y, val_pred)\n",
    "    tab_nmae.append(fold_nmae)\n",
    "    print(f\"{i + 1} Fold NMAE = {fold_nmae}\")\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    fold_pred = tab.predict(X_test_numpy)\n",
    "    tab_pred.append(fold_pred)\n",
    "\n",
    "print(f\"\\nAVG of NMAE = {np.mean(tab_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_pred = np.mean(tab_pred,axis = 0)\n",
    "tab_pred = pd.Series(tab_pred.flatten())\n",
    "tab_pred = tab_pred.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 19:32:37,154]\u001b[0m A new study created in memory with name: Xgboost Optuna\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:33:05,507]\u001b[0m Trial 0 finished with value: 0.10288669568080196 and parameters: {'lambda': 0.0752451513820885, 'alpha': 0.11734346787248895, 'colsample_bytree': 0.43510036347009773, 'subsample': 0.48182687641445304, 'learning_rate': 0.46572857368142373, 'n_estimators': 1071, 'max_depth': 14, 'min_child_weight': 26}. Best is trial 0 with value: 0.10288669568080196.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:33:46,856]\u001b[0m Trial 1 finished with value: 0.08128326406739081 and parameters: {'lambda': 0.09256396974955594, 'alpha': 0.8261306636288646, 'colsample_bytree': 0.6687992860024254, 'subsample': 0.8917307349708219, 'learning_rate': 0.042634682404854074, 'n_estimators': 1370, 'max_depth': 10, 'min_child_weight': 33}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:35:17,669]\u001b[0m Trial 2 finished with value: 0.09885929733414592 and parameters: {'lambda': 0.033309095085059026, 'alpha': 0.3616553226404266, 'colsample_bytree': 0.9792384942983365, 'subsample': 0.4475944259720703, 'learning_rate': 0.26569288617637077, 'n_estimators': 2916, 'max_depth': 15, 'min_child_weight': 42}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:37:09,071]\u001b[0m Trial 3 finished with value: 0.09586971240133943 and parameters: {'lambda': 0.06115214791510576, 'alpha': 0.3712296230167946, 'colsample_bytree': 0.5496607457698406, 'subsample': 0.5310328066333977, 'learning_rate': 0.18180166663479877, 'n_estimators': 2797, 'max_depth': 17, 'min_child_weight': 7}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:38:06,642]\u001b[0m Trial 4 finished with value: 0.09801380638823816 and parameters: {'lambda': 0.07309875814422027, 'alpha': 0.2238035423920802, 'colsample_bytree': 0.9696041153600795, 'subsample': 0.5148671274806477, 'learning_rate': 0.31225660691300694, 'n_estimators': 1188, 'max_depth': 17, 'min_child_weight': 7}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:39:30,476]\u001b[0m Trial 5 finished with value: 0.09919730970652778 and parameters: {'lambda': 0.08565431726221402, 'alpha': 0.8311185623281515, 'colsample_bytree': 0.5545141873618347, 'subsample': 0.8606256314678693, 'learning_rate': 0.24991019697021608, 'n_estimators': 2191, 'max_depth': 22, 'min_child_weight': 17}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:40:45,857]\u001b[0m Trial 6 finished with value: 0.08869885770899079 and parameters: {'lambda': 0.08211098824472218, 'alpha': 0.7169329740306613, 'colsample_bytree': 0.5349983788288388, 'subsample': 0.9572804871268097, 'learning_rate': 0.2568393336381919, 'n_estimators': 2685, 'max_depth': 10, 'min_child_weight': 5}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:41:30,459]\u001b[0m Trial 7 finished with value: 0.09083436193809404 and parameters: {'lambda': 0.06485623930544783, 'alpha': 0.12778538997507538, 'colsample_bytree': 0.7913554636294318, 'subsample': 0.9428294531820288, 'learning_rate': 0.38386944141753254, 'n_estimators': 1657, 'max_depth': 7, 'min_child_weight': 6}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:42:53,086]\u001b[0m Trial 8 finished with value: 0.09785913507066601 and parameters: {'lambda': 0.07823781829783907, 'alpha': 0.621902402353152, 'colsample_bytree': 0.8435290590069047, 'subsample': 0.9991209275902819, 'learning_rate': 0.31303515656540615, 'n_estimators': 1676, 'max_depth': 22, 'min_child_weight': 24}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:44:11,301]\u001b[0m Trial 9 finished with value: 0.0906692878069699 and parameters: {'lambda': 0.0349188622167597, 'alpha': 0.9101912977984288, 'colsample_bytree': 0.5553544990045822, 'subsample': 0.8855831774840344, 'learning_rate': 0.3167463232886177, 'n_estimators': 2320, 'max_depth': 16, 'min_child_weight': 6}. Best is trial 1 with value: 0.08128326406739081.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:44:50,250]\u001b[0m Trial 10 finished with value: 0.07515195691174334 and parameters: {'lambda': 0.002789420020014359, 'alpha': 0.9712354539594275, 'colsample_bytree': 0.7006593918779188, 'subsample': 0.7244665746615934, 'learning_rate': 0.013633932443405355, 'n_estimators': 1672, 'max_depth': 4, 'min_child_weight': 43}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:45:21,114]\u001b[0m Trial 11 finished with value: 0.07516499102788857 and parameters: {'lambda': 0.004452803726430969, 'alpha': 0.984681488616809, 'colsample_bytree': 0.6955333808909464, 'subsample': 0.7242611245351936, 'learning_rate': 0.015026311377957208, 'n_estimators': 1516, 'max_depth': 4, 'min_child_weight': 41}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:45:55,464]\u001b[0m Trial 12 finished with value: 0.07594249313267658 and parameters: {'lambda': 0.0010230243609315047, 'alpha': 0.9463063436064006, 'colsample_bytree': 0.7144201183950916, 'subsample': 0.6987376880823958, 'learning_rate': 0.020791650674804863, 'n_estimators': 1755, 'max_depth': 4, 'min_child_weight': 50}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:46:42,033]\u001b[0m Trial 13 finished with value: 0.08322472696248821 and parameters: {'lambda': 0.0027816479006494174, 'alpha': 0.9807256476536571, 'colsample_bytree': 0.6789739757205121, 'subsample': 0.7244724251915962, 'learning_rate': 0.11198758803160748, 'n_estimators': 1977, 'max_depth': 4, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:47:23,883]\u001b[0m Trial 14 finished with value: 0.08513179193161799 and parameters: {'lambda': 0.018349677350816183, 'alpha': 0.6160673917830413, 'colsample_bytree': 0.8516711057844861, 'subsample': 0.7027931611588486, 'learning_rate': 0.10327307843980997, 'n_estimators': 1458, 'max_depth': 8, 'min_child_weight': 50}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:48:15,258]\u001b[0m Trial 15 finished with value: 0.0864958207505376 and parameters: {'lambda': 0.01878703830235679, 'alpha': 0.7546037951318749, 'colsample_bytree': 0.7527567328636159, 'subsample': 0.631006352959388, 'learning_rate': 0.09302973392301211, 'n_estimators': 1930, 'max_depth': 7, 'min_child_weight': 42}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:48:41,368]\u001b[0m Trial 16 finished with value: 0.08321443857959833 and parameters: {'lambda': 0.01681621097402075, 'alpha': 0.4978046345098237, 'colsample_bytree': 0.6171615026494736, 'subsample': 0.7810288691376817, 'learning_rate': 0.163639897724612, 'n_estimators': 1358, 'max_depth': 4, 'min_child_weight': 33}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:49:59,997]\u001b[0m Trial 17 finished with value: 0.08182980221409397 and parameters: {'lambda': 0.03778836088344601, 'alpha': 0.9892614555631356, 'colsample_bytree': 0.8806933479205323, 'subsample': 0.5895747144887594, 'learning_rate': 0.03223556044064769, 'n_estimators': 2372, 'max_depth': 12, 'min_child_weight': 44}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:50:35,836]\u001b[0m Trial 18 finished with value: 0.08813342728526545 and parameters: {'lambda': 0.046806268208125126, 'alpha': 0.6444655380452609, 'colsample_bytree': 0.6227915045576675, 'subsample': 0.7860868615395155, 'learning_rate': 0.15328748834987246, 'n_estimators': 1550, 'max_depth': 6, 'min_child_weight': 34}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:51:29,440]\u001b[0m Trial 19 finished with value: 0.08898897276372572 and parameters: {'lambda': 0.012429877767321663, 'alpha': 0.8524262618011734, 'colsample_bytree': 0.4050208484976657, 'subsample': 0.6326349625510052, 'learning_rate': 0.06868028421129804, 'n_estimators': 1844, 'max_depth': 10, 'min_child_weight': 18}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:52:17,152]\u001b[0m Trial 20 finished with value: 0.09322418833146606 and parameters: {'lambda': 0.009737667974684202, 'alpha': 0.5012538739953597, 'colsample_bytree': 0.7782675720010341, 'subsample': 0.8094003347439499, 'learning_rate': 0.20513335588277026, 'n_estimators': 1256, 'max_depth': 19, 'min_child_weight': 45}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 19:52:49,274]\u001b[0m Trial 21 finished with value: 0.07683371747786825 and parameters: {'lambda': 0.0011479204473983325, 'alpha': 0.923626753858181, 'colsample_bytree': 0.7297822863365432, 'subsample': 0.6664354665636354, 'learning_rate': 0.03082939224895049, 'n_estimators': 1746, 'max_depth': 4, 'min_child_weight': 50}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:53:33,809]\u001b[0m Trial 22 finished with value: 0.0769923233100939 and parameters: {'lambda': 0.02651218846661548, 'alpha': 0.9164963243278492, 'colsample_bytree': 0.6981492712331444, 'subsample': 0.7361948719424471, 'learning_rate': 0.01657588032965461, 'n_estimators': 2097, 'max_depth': 6, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:54:03,821]\u001b[0m Trial 23 finished with value: 0.08102033503460922 and parameters: {'lambda': 0.005963385383161409, 'alpha': 0.7584080865341396, 'colsample_bytree': 0.6345461971363299, 'subsample': 0.7497597560363186, 'learning_rate': 0.07804201106852626, 'n_estimators': 1585, 'max_depth': 5, 'min_child_weight': 46}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:55:00,536]\u001b[0m Trial 24 finished with value: 0.07615832669941297 and parameters: {'lambda': 0.026604470885430363, 'alpha': 0.9802437531256496, 'colsample_bytree': 0.7965223911024467, 'subsample': 0.5743352706960421, 'learning_rate': 0.01079655903834457, 'n_estimators': 1801, 'max_depth': 8, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:55:43,177]\u001b[0m Trial 25 finished with value: 0.08222793127505987 and parameters: {'lambda': 0.009627820272433061, 'alpha': 0.8765622776170914, 'colsample_bytree': 0.7285951410855105, 'subsample': 0.6728832868111532, 'learning_rate': 0.0668181963921492, 'n_estimators': 1410, 'max_depth': 9, 'min_child_weight': 48}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:56:55,228]\u001b[0m Trial 26 finished with value: 0.094524534793569 and parameters: {'lambda': 0.024221579039298634, 'alpha': 0.0127596717017876, 'colsample_bytree': 0.9283644478233062, 'subsample': 0.8246082513220857, 'learning_rate': 0.12669421411209797, 'n_estimators': 2121, 'max_depth': 12, 'min_child_weight': 40}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:57:18,452]\u001b[0m Trial 27 finished with value: 0.08446535073902914 and parameters: {'lambda': 0.04711584901973163, 'alpha': 0.8086094175016905, 'colsample_bytree': 0.5959403033987942, 'subsample': 0.668143268106429, 'learning_rate': 0.13700653742932575, 'n_estimators': 1023, 'max_depth': 6, 'min_child_weight': 30}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:57:46,758]\u001b[0m Trial 28 finished with value: 0.07787465929812948 and parameters: {'lambda': 0.001347063725114585, 'alpha': 0.7024191393508978, 'colsample_bytree': 0.4838650405348741, 'subsample': 0.7689166372910783, 'learning_rate': 0.05514431318332869, 'n_estimators': 1519, 'max_depth': 4, 'min_child_weight': 45}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:58:27,709]\u001b[0m Trial 29 finished with value: 0.09793321312923664 and parameters: {'lambda': 0.012468163643149918, 'alpha': 0.9383518508390114, 'colsample_bytree': 0.6628689190920335, 'subsample': 0.6015210050907355, 'learning_rate': 0.20685633099475936, 'n_estimators': 1246, 'max_depth': 13, 'min_child_weight': 21}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:59:10,846]\u001b[0m Trial 30 finished with value: 0.1023077288925192 and parameters: {'lambda': 0.02388679200475594, 'alpha': 0.5235337408984307, 'colsample_bytree': 0.7180752832788463, 'subsample': 0.7003152579293488, 'learning_rate': 0.4413140580814099, 'n_estimators': 1898, 'max_depth': 6, 'min_child_weight': 28}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 19:59:59,573]\u001b[0m Trial 31 finished with value: 0.07670938225858732 and parameters: {'lambda': 0.028848242696379187, 'alpha': 0.9911923426553885, 'colsample_bytree': 0.7889345812820945, 'subsample': 0.5622031054910102, 'learning_rate': 0.013626661841566719, 'n_estimators': 1775, 'max_depth': 8, 'min_child_weight': 37}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:00:37,306]\u001b[0m Trial 32 finished with value: 0.07913287657803637 and parameters: {'lambda': 0.006770867646289951, 'alpha': 0.998857101996847, 'colsample_bytree': 0.8251676249875386, 'subsample': 0.48158380018223573, 'learning_rate': 0.046240778073332024, 'n_estimators': 1756, 'max_depth': 5, 'min_child_weight': 41}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:01:27,136]\u001b[0m Trial 33 finished with value: 0.07602212420796188 and parameters: {'lambda': 0.018561766178077813, 'alpha': 0.7958122605097454, 'colsample_bytree': 0.7559276521207826, 'subsample': 0.6207763991750824, 'learning_rate': 0.01082475159680761, 'n_estimators': 1859, 'max_depth': 8, 'min_child_weight': 47}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:02:10,009]\u001b[0m Trial 34 finished with value: 0.07862815433818474 and parameters: {'lambda': 0.015082171109267097, 'alpha': 0.812755536236347, 'colsample_bytree': 0.6612626328690883, 'subsample': 0.40413537631560364, 'learning_rate': 0.04830463141796652, 'n_estimators': 2034, 'max_depth': 5, 'min_child_weight': 47}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:02:54,045]\u001b[0m Trial 35 finished with value: 0.0828697233888591 and parameters: {'lambda': 0.007946907712801387, 'alpha': 0.8755557357927506, 'colsample_bytree': 0.7505874002170033, 'subsample': 0.6149043292914351, 'learning_rate': 0.0834327405885579, 'n_estimators': 1630, 'max_depth': 7, 'min_child_weight': 50}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:04:08,030]\u001b[0m Trial 36 finished with value: 0.08370042877009128 and parameters: {'lambda': 0.09919040747155985, 'alpha': 0.764322954671213, 'colsample_bytree': 0.888806470539689, 'subsample': 0.6608069216325939, 'learning_rate': 0.04077519613307597, 'n_estimators': 2323, 'max_depth': 11, 'min_child_weight': 43}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:04:42,028]\u001b[0m Trial 37 finished with value: 0.07764860388048508 and parameters: {'lambda': 0.02155537200030892, 'alpha': 0.37504255247447055, 'colsample_bytree': 0.6890561268737532, 'subsample': 0.5426392830282954, 'learning_rate': 0.011207046825940445, 'n_estimators': 1152, 'max_depth': 9, 'min_child_weight': 12}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:05:07,560]\u001b[0m Trial 38 finished with value: 0.0822648895768914 and parameters: {'lambda': 0.04107107940857655, 'alpha': 0.9305837624268953, 'colsample_bytree': 0.5922290483803319, 'subsample': 0.8388778692416026, 'learning_rate': 0.1132262829422502, 'n_estimators': 1339, 'max_depth': 5, 'min_child_weight': 34}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:05:58,130]\u001b[0m Trial 39 finished with value: 0.09864377722057387 and parameters: {'lambda': 0.0058875917422133595, 'alpha': 0.8687835136994284, 'colsample_bytree': 0.7542161195271171, 'subsample': 0.7146717862613364, 'learning_rate': 0.46237109064502796, 'n_estimators': 2552, 'max_depth': 4, 'min_child_weight': 48}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:06:47,541]\u001b[0m Trial 40 finished with value: 0.10144387046235001 and parameters: {'lambda': 0.05836015826187609, 'alpha': 0.8030063984730469, 'colsample_bytree': 0.6522241691099353, 'subsample': 0.750751025322198, 'learning_rate': 0.37628259042046175, 'n_estimators': 1478, 'max_depth': 14, 'min_child_weight': 42}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:07:40,779]\u001b[0m Trial 41 finished with value: 0.07570816147462407 and parameters: {'lambda': 0.014290384501302189, 'alpha': 0.9477884028890367, 'colsample_bytree': 0.824676941663424, 'subsample': 0.49571533857083644, 'learning_rate': 0.01001715534035715, 'n_estimators': 1834, 'max_depth': 8, 'min_child_weight': 39}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 20:08:23,367]\u001b[0m Trial 42 finished with value: 0.08083620087835144 and parameters: {'lambda': 0.013371778363509224, 'alpha': 0.9384853558279184, 'colsample_bytree': 0.814315156699654, 'subsample': 0.4926063233642244, 'learning_rate': 0.06594993742313962, 'n_estimators': 1664, 'max_depth': 7, 'min_child_weight': 47}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:09:18,739]\u001b[0m Trial 43 finished with value: 0.07974143338236248 and parameters: {'lambda': 0.031257170110686155, 'alpha': 0.8782946474267448, 'colsample_bytree': 0.7644167478421445, 'subsample': 0.4407496026129335, 'learning_rate': 0.03720913564734785, 'n_estimators': 1883, 'max_depth': 10, 'min_child_weight': 40}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:10:29,842]\u001b[0m Trial 44 finished with value: 0.09007283479062292 and parameters: {'lambda': 0.0034644571201854235, 'alpha': 0.9537572462533882, 'colsample_bytree': 0.8572727184983976, 'subsample': 0.6376743609491756, 'learning_rate': 0.09667016550918434, 'n_estimators': 2237, 'max_depth': 19, 'min_child_weight': 44}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:11:26,253]\u001b[0m Trial 45 finished with value: 0.08112942808110221 and parameters: {'lambda': 0.01994444902816894, 'alpha': 0.7070205734932429, 'colsample_bytree': 0.7171954184284729, 'subsample': 0.6915713218260067, 'learning_rate': 0.031515530567363545, 'n_estimators': 1996, 'max_depth': 9, 'min_child_weight': 36}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:12:07,911]\u001b[0m Trial 46 finished with value: 0.08146719492784023 and parameters: {'lambda': 0.016336916668706673, 'alpha': 0.8390982008670549, 'colsample_bytree': 0.943932479192789, 'subsample': 0.5371114461490308, 'learning_rate': 0.06176917451929708, 'n_estimators': 1708, 'max_depth': 5, 'min_child_weight': 30}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:12:48,495]\u001b[0m Trial 47 finished with value: 0.08308336835448908 and parameters: {'lambda': 0.009892681038746944, 'alpha': 0.30051245599795834, 'colsample_bytree': 0.8189626376981356, 'subsample': 0.5070488091154098, 'learning_rate': 0.09257294887319223, 'n_estimators': 1590, 'max_depth': 24, 'min_child_weight': 48}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:13:52,391]\u001b[0m Trial 48 finished with value: 0.0791925342800599 and parameters: {'lambda': 0.0014039923506637218, 'alpha': 0.8958446676249067, 'colsample_bytree': 0.6950923762212035, 'subsample': 0.8033238487865169, 'learning_rate': 0.01029285588574477, 'n_estimators': 1943, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:14:33,246]\u001b[0m Trial 49 finished with value: 0.09365223838069098 and parameters: {'lambda': 0.06688176124696738, 'alpha': 0.653876352858899, 'colsample_bytree': 0.7393011940964814, 'subsample': 0.453703325530713, 'learning_rate': 0.29013379197444633, 'n_estimators': 1829, 'max_depth': 6, 'min_child_weight': 41}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:15:34,557]\u001b[0m Trial 50 finished with value: 0.0915068954564693 and parameters: {'lambda': 0.012090920154248008, 'alpha': 0.775455180672788, 'colsample_bytree': 0.8845621830989845, 'subsample': 0.8757121942683834, 'learning_rate': 0.12311397499347217, 'n_estimators': 2050, 'max_depth': 8, 'min_child_weight': 35}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:16:28,921]\u001b[0m Trial 51 finished with value: 0.07972363810062949 and parameters: {'lambda': 0.00588705148880757, 'alpha': 0.9509335285037368, 'colsample_bytree': 0.8038607037639078, 'subsample': 0.5666778935560508, 'learning_rate': 0.030086805725877783, 'n_estimators': 1822, 'max_depth': 8, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:17:25,071]\u001b[0m Trial 52 finished with value: 0.0766599455648442 and parameters: {'lambda': 0.01889052120375243, 'alpha': 0.9987935252564552, 'colsample_bytree': 0.7798320616966017, 'subsample': 0.592485206327553, 'learning_rate': 0.013578295290263892, 'n_estimators': 1691, 'max_depth': 12, 'min_child_weight': 43}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:18:23,947]\u001b[0m Trial 53 finished with value: 0.07940753885454076 and parameters: {'lambda': 0.037400688413684297, 'alpha': 0.9579056339486791, 'colsample_bytree': 0.8368421339795635, 'subsample': 0.6371778681097622, 'learning_rate': 0.05439515899323845, 'n_estimators': 1805, 'max_depth': 4, 'min_child_weight': 32}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:19:58,042]\u001b[0m Trial 54 finished with value: 0.08976682870130731 and parameters: {'lambda': 0.022783411777379827, 'alpha': 0.9688357293742154, 'colsample_bytree': 0.7169481858705679, 'subsample': 0.5701543597873435, 'learning_rate': 0.07740020644607545, 'n_estimators': 2896, 'max_depth': 15, 'min_child_weight': 39}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:20:40,276]\u001b[0m Trial 55 finished with value: 0.07910996182667604 and parameters: {'lambda': 0.015835839111740677, 'alpha': 0.9045931448147125, 'colsample_bytree': 0.7697549435026936, 'subsample': 0.7396617329473575, 'learning_rate': 0.03013083015769214, 'n_estimators': 1538, 'max_depth': 9, 'min_child_weight': 45}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:21:22,457]\u001b[0m Trial 56 finished with value: 0.07832701020289363 and parameters: {'lambda': 0.02795185817389435, 'alpha': 0.8448052039632599, 'colsample_bytree': 0.8628323114504158, 'subsample': 0.6823459714406277, 'learning_rate': 0.027060099557216465, 'n_estimators': 1414, 'max_depth': 11, 'min_child_weight': 50}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:22:15,948]\u001b[0m Trial 57 finished with value: 0.08210604602111533 and parameters: {'lambda': 0.004196609726441623, 'alpha': 0.9025037096103338, 'colsample_bytree': 0.6756246920177054, 'subsample': 0.7180958770015212, 'learning_rate': 0.05001723306124273, 'n_estimators': 2136, 'max_depth': 5, 'min_child_weight': 24}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:22:53,738]\u001b[0m Trial 58 finished with value: 0.0817158292976313 and parameters: {'lambda': 0.01060130636579536, 'alpha': 0.5704195115946021, 'colsample_bytree': 0.6346768856010075, 'subsample': 0.5225231254445276, 'learning_rate': 0.07542830699357345, 'n_estimators': 1624, 'max_depth': 7, 'min_child_weight': 46}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:23:46,034]\u001b[0m Trial 59 finished with value: 0.09486800012515477 and parameters: {'lambda': 0.05397617016144912, 'alpha': 0.8442065582097352, 'colsample_bytree': 0.7910778158253008, 'subsample': 0.7638701493134535, 'learning_rate': 0.23683660163708184, 'n_estimators': 1933, 'max_depth': 6, 'min_child_weight': 36}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:24:24,942]\u001b[0m Trial 60 finished with value: 0.08474186831075319 and parameters: {'lambda': 0.009401334120927496, 'alpha': 0.917897147350403, 'colsample_bytree': 0.7431388760360662, 'subsample': 0.6047537125336869, 'learning_rate': 0.14584716054204372, 'n_estimators': 1879, 'max_depth': 4, 'min_child_weight': 43}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:25:18,510]\u001b[0m Trial 61 finished with value: 0.07684095407700223 and parameters: {'lambda': 0.019007368811434746, 'alpha': 0.9858419526468118, 'colsample_bytree': 0.7857214914889038, 'subsample': 0.6433299749814628, 'learning_rate': 0.013136137546892121, 'n_estimators': 1705, 'max_depth': 13, 'min_child_weight': 43}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:26:09,040]\u001b[0m Trial 62 finished with value: 0.07874886637608665 and parameters: {'lambda': 0.03139516248538291, 'alpha': 0.9991525658195863, 'colsample_bytree': 0.7049013318626145, 'subsample': 0.5727854879629096, 'learning_rate': 0.02430638105183138, 'n_estimators': 1719, 'max_depth': 17, 'min_child_weight': 40}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 20:27:05,155]\u001b[0m Trial 63 finished with value: 0.08045226979483422 and parameters: {'lambda': 0.014572522322529896, 'alpha': 0.963894416745883, 'colsample_bytree': 0.7679600679381183, 'subsample': 0.5881181819013023, 'learning_rate': 0.044801949251760884, 'n_estimators': 1662, 'max_depth': 11, 'min_child_weight': 49}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:27:53,612]\u001b[0m Trial 64 finished with value: 0.08170304920803709 and parameters: {'lambda': 0.025000471285932465, 'alpha': 0.9574678243632119, 'colsample_bytree': 0.9053744456930848, 'subsample': 0.5442904491230743, 'learning_rate': 0.06042857515795302, 'n_estimators': 1470, 'max_depth': 12, 'min_child_weight': 46}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:28:40,344]\u001b[0m Trial 65 finished with value: 0.0762178386452755 and parameters: {'lambda': 0.01765326310538638, 'alpha': 0.9022170072688273, 'colsample_bytree': 0.8356165580389304, 'subsample': 0.6547285894358851, 'learning_rate': 0.010718529625350894, 'n_estimators': 1548, 'max_depth': 10, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:29:37,673]\u001b[0m Trial 66 finished with value: 0.08097705887260807 and parameters: {'lambda': 0.004497362053410865, 'alpha': 0.789759487114039, 'colsample_bytree': 0.8485641156917035, 'subsample': 0.6155874205726533, 'learning_rate': 0.03350925592623774, 'n_estimators': 1592, 'max_depth': 10, 'min_child_weight': 32}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:30:15,452]\u001b[0m Trial 67 finished with value: 0.08464563468364109 and parameters: {'lambda': 0.008551016588295601, 'alpha': 0.8982320825741911, 'colsample_bytree': 0.8004943028405621, 'subsample': 0.6485794271777588, 'learning_rate': 0.08605218698612589, 'n_estimators': 1337, 'max_depth': 8, 'min_child_weight': 38}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:30:58,745]\u001b[0m Trial 68 finished with value: 0.08435190509047467 and parameters: {'lambda': 0.021613705192792185, 'alpha': 0.7260009343388155, 'colsample_bytree': 0.8264734511345448, 'subsample': 0.9160418813550499, 'learning_rate': 0.10647883035320896, 'n_estimators': 1759, 'max_depth': 6, 'min_child_weight': 41}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:31:42,877]\u001b[0m Trial 69 finished with value: 0.09259393523146628 and parameters: {'lambda': 0.013317120849805927, 'alpha': 0.8706505032046509, 'colsample_bytree': 0.7313342444694573, 'subsample': 0.6958638417491755, 'learning_rate': 0.17440720975673807, 'n_estimators': 1533, 'max_depth': 9, 'min_child_weight': 36}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:32:14,909]\u001b[0m Trial 70 finished with value: 0.07929540888307006 and parameters: {'lambda': 0.017524854455125093, 'alpha': 0.4197549017870695, 'colsample_bytree': 0.6856946812870468, 'subsample': 0.6587861053761245, 'learning_rate': 0.04435860589551922, 'n_estimators': 1282, 'max_depth': 7, 'min_child_weight': 39}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:33:09,259]\u001b[0m Trial 71 finished with value: 0.07651421173986589 and parameters: {'lambda': 0.0076158800917007895, 'alpha': 0.9390973159525897, 'colsample_bytree': 0.7751643918308779, 'subsample': 0.7282436240008251, 'learning_rate': 0.011195787929226977, 'n_estimators': 1799, 'max_depth': 11, 'min_child_weight': 44}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:33:56,404]\u001b[0m Trial 72 finished with value: 0.07598678838007364 and parameters: {'lambda': 0.007539855636907586, 'alpha': 0.9346789948717698, 'colsample_bytree': 0.7578703141085945, 'subsample': 0.7268947928051801, 'learning_rate': 0.010205088728632095, 'n_estimators': 1864, 'max_depth': 8, 'min_child_weight': 45}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:34:51,419]\u001b[0m Trial 73 finished with value: 0.07822409451939967 and parameters: {'lambda': 0.0013016640483382957, 'alpha': 0.9241067872635074, 'colsample_bytree': 0.9987191027973095, 'subsample': 0.7855264997043663, 'learning_rate': 0.02124472443722701, 'n_estimators': 1866, 'max_depth': 8, 'min_child_weight': 47}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:35:35,034]\u001b[0m Trial 74 finished with value: 0.08068330972168691 and parameters: {'lambda': 0.004427868124640343, 'alpha': 0.8283988589782915, 'colsample_bytree': 0.7098954858253785, 'subsample': 0.713076607951499, 'learning_rate': 0.055369275556722566, 'n_estimators': 1950, 'max_depth': 5, 'min_child_weight': 42}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:36:24,518]\u001b[0m Trial 75 finished with value: 0.09893610893276278 and parameters: {'lambda': 0.012532103422938408, 'alpha': 0.12155336013421786, 'colsample_bytree': 0.7535775787846501, 'subsample': 0.6176917168873536, 'learning_rate': 0.3413999836819649, 'n_estimators': 1780, 'max_depth': 9, 'min_child_weight': 45}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:37:27,765]\u001b[0m Trial 76 finished with value: 0.08176871603450805 and parameters: {'lambda': 0.007638729898254525, 'alpha': 0.969208178258705, 'colsample_bytree': 0.8075841983071229, 'subsample': 0.6819799674436695, 'learning_rate': 0.04002306975622684, 'n_estimators': 2037, 'max_depth': 10, 'min_child_weight': 49}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:37:53,841]\u001b[0m Trial 77 finished with value: 0.07880154378895267 and parameters: {'lambda': 0.01150441899994783, 'alpha': 0.19466959799363498, 'colsample_bytree': 0.6498008606325687, 'subsample': 0.7070615094646807, 'learning_rate': 0.06835514841607816, 'n_estimators': 1409, 'max_depth': 4, 'min_child_weight': 48}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:38:41,979]\u001b[0m Trial 78 finished with value: 0.08240322605867155 and parameters: {'lambda': 0.04243342957623948, 'alpha': 0.88356115194343, 'colsample_bytree': 0.8309834587304288, 'subsample': 0.7386300609860489, 'learning_rate': 0.03126025411643037, 'n_estimators': 1619, 'max_depth': 6, 'min_child_weight': 10}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:39:32,826]\u001b[0m Trial 79 finished with value: 0.07740704881131863 and parameters: {'lambda': 0.01555823447725721, 'alpha': 0.9137446021032465, 'colsample_bytree': 0.8683875426103276, 'subsample': 0.6750365781757516, 'learning_rate': 0.022667938398073042, 'n_estimators': 1482, 'max_depth': 7, 'min_child_weight': 39}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:40:37,597]\u001b[0m Trial 80 finished with value: 0.08125241263113628 and parameters: {'lambda': 0.08993809344797186, 'alpha': 0.933108796388335, 'colsample_bytree': 0.905778588271551, 'subsample': 0.45811077186657256, 'learning_rate': 0.04701218444311009, 'n_estimators': 2003, 'max_depth': 8, 'min_child_weight': 41}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:41:29,497]\u001b[0m Trial 81 finished with value: 0.07633873294268877 and parameters: {'lambda': 0.007154604911871174, 'alpha': 0.8571594238656285, 'colsample_bytree': 0.7306802394520083, 'subsample': 0.7645744516820145, 'learning_rate': 0.010383247477530822, 'n_estimators': 1789, 'max_depth': 11, 'min_child_weight': 44}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:42:09,721]\u001b[0m Trial 82 finished with value: 0.07665147583828154 and parameters: {'lambda': 0.0030510928831923387, 'alpha': 0.8703738760970898, 'colsample_bytree': 0.7279179089678742, 'subsample': 0.8029345265825256, 'learning_rate': 0.02193434287910085, 'n_estimators': 1856, 'max_depth': 5, 'min_child_weight': 46}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:42:59,888]\u001b[0m Trial 83 finished with value: 0.07674359445401657 and parameters: {'lambda': 0.006149622454554015, 'alpha': 0.8501685160714755, 'colsample_bytree': 0.6739671363442366, 'subsample': 0.7729189973187478, 'learning_rate': 0.012227434240497808, 'n_estimators': 1734, 'max_depth': 13, 'min_child_weight': 44}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-13 20:44:00,571]\u001b[0m Trial 84 finished with value: 0.08255966516239441 and parameters: {'lambda': 0.020653565697852004, 'alpha': 0.9757466530729391, 'colsample_bytree': 0.7580269668308595, 'subsample': 0.752450579833337, 'learning_rate': 0.039830319317035165, 'n_estimators': 1917, 'max_depth': 10, 'min_child_weight': 37}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n",
      "\u001b[32m[I 2022-12-13 20:44:43,939]\u001b[0m Trial 85 finished with value: 0.07793593731634205 and parameters: {'lambda': 0.009555414789189554, 'alpha': 0.8143456759751999, 'colsample_bytree': 0.7387846062401654, 'subsample': 0.6557367657652059, 'learning_rate': 0.023409113214057135, 'n_estimators': 1569, 'max_depth': 9, 'min_child_weight': 49}. Best is trial 10 with value: 0.07515195691174334.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d1bfdbf68863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mstudy_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-d1bfdbf68863>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#cross_val optuna searching method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMAE_CV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         )\n\u001b[1;32m--> 961\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    962\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ai_prog2\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1733\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1734\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    kf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    #train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "    param = {\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 0.1),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.01, 0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4,24),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 50),\n",
    "    }\n",
    "    model = XGBRegressor(**param)  \n",
    "    \"\"\"\n",
    "    base optuna searching method\n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100, eval_metric='mae')\n",
    "    preds = model.predict(test_x).astype(int)\n",
    "    nmae = NMAE(test_y, preds)\n",
    "    return nmae\n",
    "    \"\"\"\n",
    "    #cross_val optuna searching method\n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = NMAE_CV).mean()\n",
    "    return score\n",
    "          \n",
    "study_xgb = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name = 'Xgboost Optuna', \n",
    "    sampler=sampler\n",
    ")\n",
    "study_xgb.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_xgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {\n",
    "    'objective' : 'reg:squarederror',\n",
    "    'tree_method' : 'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor'\n",
    "}\n",
    "xgb_best_params = study_xgb.best_params.copy()\n",
    "xgb_best_params.update(xgb_param)\n",
    "xgb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold\n",
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "def custom_NMAE(y_pred, Dmatrix):\n",
    "    true = Dmatrix.get_label()\n",
    "    mae = np.mean(np.abs(true - y_pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return ('custom_NMAE', score)\n",
    "\"\"\"\n",
    "xgb_pred = []\n",
    "\n",
    "kfold_list = [2, 3, 4, 5, 6, 10, 20]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    xgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \"\"\"\n",
    "        파이썬 래퍼 XGB 데이터 셋 변환\n",
    "        train = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        valid = xgb.DMatrix(val_x, label=val_y)\n",
    "        test = xgb.DMatrix(X_test)\n",
    "        \"\"\"\n",
    "        #사이킷 런 래퍼 XGB 학습\n",
    "        xgb = XGBRegressor(**xgb_best_params)\n",
    "        xgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')       \n",
    "        val_pred = xgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        xgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = xgb.predict(X_test)\n",
    "        xgb_pred.append(fold_pred)\n",
    "        \n",
    "        \"\"\"\n",
    "        파이썬 래퍼 XGB 학습\n",
    "        model = xgb.train(**xgb_best_params, train, \n",
    "                          num_boost_round = 1000, \n",
    "                          early_stopping_rounds = 100,\n",
    "                          verbose = 50,\n",
    "                          evals=[(valid, 'valid')], \n",
    "                          feval=custom_NMAE)\n",
    "        \"\"\"\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(xgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred_sum = sum(xgb_pred)  \n",
    "xgb_pred_sum /= len(xgb_pred)\n",
    "xgb_pred_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    kf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    #train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3,random_state=42)\n",
    "    param = {'num_leaves': trial.suggest_int('num_leaves', 10, 400), \n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 24), \n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5), \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1000, 3000), \n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 50), \n",
    "            'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), \n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 1.0),\n",
    "            'random_state': 42}\n",
    "    model =LGBMRegressor(**param)  \n",
    "    \n",
    "    \"\"\"\n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,eval_metric='mae')\n",
    "    preds = model.predict(test_x).astype(int)\n",
    "    nmae = NMAE(test_y, preds)\n",
    "    return nmae\n",
    "    \"\"\"\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv = kf, scoring = NMAE_CV).mean()\n",
    "    return score\n",
    "          \n",
    "study_lgb = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name = 'LGBM Optuna', \n",
    "    sampler=sampler\n",
    ")\n",
    "study_lgb.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param = {\n",
    "    'objective' : 'regression',\n",
    "    'device' : 'gpu',\n",
    "    'metric' : 'mae',\n",
    "}\n",
    "lgb_best_params = study_lgb.best_params.copy()\n",
    "lgb_best_params.update(lgb_param)\n",
    "lgb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold\n",
    "lgb_pred = []\n",
    "\n",
    "kfold_list = [2, 3, 4, 5, 6, 10, 20]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    lgb_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        lgb = LGBMRegressor(**lgb_param)\n",
    "        lgb.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50, eval_metric = 'mae')\n",
    "        val_pred = lgb.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        lgb_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = lgb.predict(X_test)\n",
    "        lgb_pred.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(lgb_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred_sum = sum(lgb_pred)  \n",
    "lgb_pred_sum /= len(lgb_pred)\n",
    "lgb_pred_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatboostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi-kfold\n",
    "cat_pred = []\n",
    "\n",
    "kfold_list = [2, 3, 4, 5, 6, 10, 20]\n",
    "for kfold in kfold_list:\n",
    "    print(f\"{kfold} Fold start\")\n",
    "    i = 0\n",
    "    cat_nmae = []\n",
    "    kf = KFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "        val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        cat = CatBoostRegressor(max_depth = 4, learning_rate = 0.01, use_best_model = True, iterations = 3000, eval_metric = 'MAE')\n",
    "        cat.fit(tr_x, tr_y, eval_set = [(val_x, val_y)], early_stopping_rounds = 100, verbose = 50)\n",
    "        val_pred = cat.predict(val_x).astype(int)\n",
    "        fold_nmae = NMAE(val_y, val_pred)\n",
    "        cat_nmae.append(fold_nmae)\n",
    "        print(f\"{i + 1}/{kfold} Fold NMAE = {fold_nmae}\")\n",
    "        i += 1\n",
    "        fold_pred = cat.predict(X_test)\n",
    "        cat_pred.append(fold_pred)\n",
    "\n",
    "    print(f\"\\nAVG of NMAE = {np.mean(cat_nmae)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred_sum = sum(cat_pred)  \n",
    "cat_pred_sum /= len(cat_pred)\n",
    "cat_pred_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission['착과량(int)'] = xgb_pred_sum*0.5 + lgb_pred_sum*0.3 + cat_pred_sum*0.2\n",
    "#submission['착과량(int)'] = np.round(submission['착과량(int)']) #정수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98YK7PKo_vpH"
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.509528Z",
     "iopub.status.busy": "2022-09-04T08:36:50.509160Z",
     "iopub.status.idle": "2022-09-04T08:36:51.514580Z",
     "shell.execute_reply": "2022-09-04T08:36:51.514002Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.509512Z"
    },
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1660337680866,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "Zfc0iZnUrPs6"
   },
   "outputs": [],
   "source": [
    "# submission.to_csv('./multi_kfold2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lg_antenna_ensemble.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c239fde4eb24d585007cef1e495495261fb6bbf5570e219d9bc38ff69d41be2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
